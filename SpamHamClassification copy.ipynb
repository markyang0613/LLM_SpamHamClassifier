{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e53d8015-5d26-4e51-8bba-2ae3cbae17ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marksmacbookair/miniconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/marksmacbookair/.cache/kagglehub/datasets/ashfakyeafi/spam-email-classification/versions/3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"ashfakyeafi/spam-email-classification\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b947c6f-4c4d-441d-adcf-4ff06bfc3272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./spam-email-classification\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od \n",
    "import pandas \n",
    "\n",
    "od.download( \n",
    "\t\"https://www.kaggle.com/datasets/ashfakyeafi/spam-email-classification/data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9951f3-aaf8-443b-8930-75837ccb9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:\n",
      "   Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Download the dataset\n",
    "dataset_path = kagglehub.dataset_download(\"ashfakyeafi/spam-email-classification\")\n",
    "\n",
    "file_path = f\"{dataset_path}/email.csv\"\n",
    "\n",
    "emails = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first 5 records\n",
    "print(\"First 5 records:\\n\", emails.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2bccf05-a4f3-4d36-b4b4-abbcf09bdf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "emails.columns = emails.columns.str.strip().str.lower()\n",
    "\n",
    "# Open a file to write JSONL format\n",
    "with open('spam_ham_dataset.jsonl', 'w', encoding='utf-8') as outfile:\n",
    "    for _, row in emails.iterrows():\n",
    "        entry = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row[\"message\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"category\"]}\n",
    "            ]\n",
    "        }\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f97244-31d5-4634-96e0-076739ec1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = '********************'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b636b31-d540-487d-b7b8-5116d7111458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-BM9QsgTit66wGmf44HrFfx\n"
     ]
    }
   ],
   "source": [
    "file = openai.files.create(\n",
    "  file=open(\"spam_ham_dataset.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "print(file.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dddd4b54-dfb5-472c-9d84-bf73440a5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-QP9nklaffp7P9Pvy6Vwgdf7s', created_at=1743375011, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-kl35lFMDQ0CAqAfBpssxQbOj', result_files=[], seed=878374318, status='validating_files', trained_tokens=None, training_file='file-HfPLP3dYpBxC7yuZX2Zgfb', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs='auto')), type='supervised'), user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "fine_tune_response = openai.fine_tuning.jobs.create(\n",
    "    training_file='file-HfPLP3dYpBxC7yuZX2Zgfb',\n",
    "    model='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "print(fine_tune_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61821987-55e4-433f-ae9a-ad7c5f548793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-B6SnKRT9PeUA1gt764jyqp1O', created_at=1743195117, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::BGBqjRQe', finished_at=1743198495, hyperparameters=Hyperparameters(batch_size=11, learning_rate_multiplier=2.0, n_epochs=3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-kl35lFMDQ0CAqAfBpssxQbOj', result_files=['file-H85EB9SEoNDghzUsm4Qfs2'], seed=205853128, status='succeeded', trained_tokens=541497, training_file='file-HfPLP3dYpBxC7yuZX2Zgfb', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=11, learning_rate_multiplier=2.0, n_epochs=3)), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the progress in fine tuning.\n",
    "openai.fine_tuning.jobs.retrieve(\"ftjob-B6SnKRT9PeUA1gt764jyqp1O\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4f9e3fc-1aa2-48f1-ad45-4c2d2fde65ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: spam\n"
     ]
    }
   ],
   "source": [
    "# Testing!\n",
    "response = openai.chat.completions.create(\n",
    "    model='ft:gpt-3.5-turbo-0125:personal::BGBqjRQe',\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"You won a $1000 gift card, click here!\"}\n",
    "    ],\n",
    "    max_tokens=1,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "classification = response.choices[0].message.content.strip()\n",
    "print(f\"Classification: {classification}\")  # Should output: \"spam\" or \"ham\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd02f0-f9ed-4ca5-93ce-fe78179dc6c4",
   "metadata": {},
   "source": [
    "### Accuracy Overview\n",
    "Now that I've confirmed that the function works and outputs something, it is time to put a confusion matrix and measure the accuracy of the model after finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a406470-a01a-4efe-a951-3f702dcb2f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[88  0]\n",
      " [ 1 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99        88\n",
      "        spam       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.96      0.98       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import re\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "# prompt = f\"\"\"Classify the following SMS message as ham or spam, and return the probability of it being spam.\n",
    "# Message: '{message}'\n",
    "# Output only: ham or spam, and the probability with two decimal points.\n",
    "# \"\"\"\n",
    "for i in range(100): \n",
    "    \n",
    "    random_number = random.randint(1, len(emails))\n",
    "    true_label = emails[\"category\"][random_number]\n",
    "    message = emails[\"message\"][random_number]\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "    model='ft:gpt-3.5-turbo-0125:personal::BGBqjRQe',\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ],\n",
    "    max_tokens=1,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "    # Extract predicted label\n",
    "    predicted_label = str(response.choices[0].message.content.strip())\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=[\"ham\", \"spam\"])\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, labels=[\"ham\", \"spam\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf908a5-857b-426b-833c-3e98ff9d17f4",
   "metadata": {},
   "source": [
    "# Confusion Matrix Breakdown:\n",
    "\n",
    "Ham: Out of 88 ham messages, all were correctly classified (88 true negatives, 0 false positives).\n",
    "\n",
    "Spam: Out of 12 spam messages, 11 were correctly identified as spam and only 1 was misclassified as ham (1 false negative).\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Ham: Precision is 0.99, and recall is 1.00, which means the model is almost perfect in identifying ham messages.\n",
    "\n",
    "Spam: Precision is perfect (1.00), indicating that every message predicted as spam was indeed spam. However, the recall is 0.92, meaning 8% of spam messages were missed.\n",
    "\n",
    "Overall Accuracy: The model achieves 99% accuracy, with both macro and weighted averages above 0.96, reflecting very high performance across both classes.\n",
    "\n",
    "Conclusion:\n",
    "The model performs nearly flawlessly with an overall accuracy of 99%. The only slight shortfall is the one misclassified spam message, which lowers the spam recall to 92%. This could be a focus for further refinement, but overall, the model is highly effective for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a56ba-dac3-4dc9-8c2f-21ae0d18f50f",
   "metadata": {},
   "source": [
    "## Shocking result of Current LLM Model\n",
    "I tried just using the current ChatGPT model (GPT 3.5) without training and fine tuning to classify spam/ham email content and the results were shocking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5abc07b-46d8-48b0-a6bb-e248ab416691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following sms message as ham or spam. Also return the probability of it being spam.\n",
      "Message: 'category                                           ham\n",
      "message     Im good! I have been thinking about you...\n",
      "Name: 4822, dtype: object'.\n",
      "The output should only contain two words: ham or spam, and the probability with two decimal points.\n",
      "\n",
      "=============================\n",
      "This email is ham, 0.01\n"
     ]
    }
   ],
   "source": [
    "message = emails.iloc[random.randint(1, len(emails))]\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = \"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\",\n",
    ")\n",
    "prompt = f\"\"\"Classify the following sms message as ham or spam. Also return the probability of it being spam.\n",
    "Message: '{message}'.\n",
    "The output should only contain two words: ham or spam, and the probability with two decimal points.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature = 0.0,\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"This email is \" + response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b398eac9-c107-42e2-941e-e73b4f25887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[81  2]\n",
      " [ 1 16]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.98        83\n",
      "        spam       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.94      0.96      0.95       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(100): \n",
    "    random_number = random.randint(1, len(emails))\n",
    "    true_label = emails[\"category\"][random_number]\n",
    "    message = emails[\"message\"][random_number]\n",
    "\n",
    "    prompt = f\"\"\"Classify the following sms message as ham or spam. \n",
    "Message: '{message}'\n",
    "Output only: ham or spam\n",
    "              \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    # Extract predicted label\n",
    "    predicted_label = str(response.choices[0].message.content)\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=[\"ham\", \"spam\"])\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, labels=[\"ham\", \"spam\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5b8ef-b533-447a-a222-08fecc2ade9b",
   "metadata": {},
   "source": [
    "# Confusion Matrix Breakdown:\n",
    "\n",
    "Ham (Actual 83):\n",
    "\n",
    "81 correctly classified as ham (true negatives).\n",
    "\n",
    "2 misclassified as spam (false positives for spam).\n",
    "\n",
    "Spam (Actual 17):\n",
    "\n",
    "16 correctly classified as spam (true positives).\n",
    "\n",
    "1 misclassified as ham (false negative).\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Ham:\n",
    "\n",
    "Precision: 0.99, meaning nearly all messages predicted as ham are indeed ham.\n",
    "\n",
    "Recall: 0.98, so 98% of actual ham messages were correctly identified.\n",
    "\n",
    "F1-Score: 0.98, reflecting excellent balance between precision and recall.\n",
    "\n",
    "Spam:\n",
    "\n",
    "Precision: 0.89, which indicates that about 11% of messages predicted as spam are actually ham.\n",
    "\n",
    "Recall: 0.94, meaning the model caught 94% of actual spam messages.\n",
    "\n",
    "F1-Score: 0.91, showing strong performance, though slightly lower than for ham.\n",
    "\n",
    "## Overall Accuracy:\n",
    "The model achieves a 97% accuracy on the dataset, with both macro and weighted averages indicating robust performance.\n",
    "\n",
    "## Conclusion:\n",
    "The classifier performs very well overall, with only minor misclassifications. While ham messages are almost perfectly recognized, there’s a small drop in spam precision, suggesting a few ham messages are mistakenly flagged as spam. This performance is strong, but further tuning might help to balance the precision-recall trade-off for spam if that’s critical for your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d21e2-9db5-4029-9eff-15659dd8d17f",
   "metadata": {},
   "source": [
    "\n",
    "# Comparison of the Two Confusion Matrices\n",
    "Both reports yield overall accuracies above 97%, indicating that the model is reliably distinguishing between ham and spam.\n",
    "\n",
    "### Class-Specific Performance:\n",
    "\n",
    "Ham messages: The model rarely misclassifies ham, with near-perfect performance.\n",
    "\n",
    "Spam messages: While one misclassification is common in both reports, the precision and recall remain strong, although the second report shows a minor drop in spam precision (0.89), suggesting a few ham messages might be incorrectly flagged as spam.\n",
    "\n",
    "Surprising Effectiveness of a Non-Finetuned Model:\n",
    "\n",
    "Unexpected Competence:\n",
    "Despite not being fine-tuned for spam detection, the regular ChatGPT-3.5 model demonstrates very high accuracy. This is surprising because one might expect a model specialized on this task to significantly outperform a general-purpose language model.\n",
    "\n",
    "Broad Training Data:\n",
    "The model’s impressive performance can be attributed to its extensive pre-training on a diverse dataset, which includes a wide range of text genres and patterns. This broad exposure allows it to implicitly learn features useful for distinguishing spam from ham.\n",
    "\n",
    "Robust Language Understanding:\n",
    "ChatGPT's strong natural language understanding capabilities enable it to pick up on subtle cues in the messages that differentiate spam from legitimate messages, even without explicit fine-tuning.\n",
    "\n",
    "Final Thoughts\n",
    "The high performance of the regular ChatGPT-3.5 model on this classification task is both encouraging and a testament to the power of large-scale language models. However, keep in mind:\n",
    "\n",
    "Consistency:\n",
    "Performance might vary with different prompt formulations or datasets.\n",
    "\n",
    "Fine-Tuning Potential:\n",
    "While the base model already performs remarkably well, targeted fine-tuning could further optimize accuracy, especially for edge cases or more nuanced spam messages.\n",
    "\n",
    "In summary, these results highlight how versatile and robust modern LLMs are, even for specialized tasks like spam detection, despite not being explicitly trained for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b403b-8883-4c64-ae69-74437a4d5fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
